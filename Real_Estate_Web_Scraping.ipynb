{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g8v3cCPR8ExD"
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "import csv\n",
        "\n",
        "def scrape_data(url, writer, category):\n",
        "    response = requests.get(url)\n",
        "    html_content = response.content\n",
        "    soup = BeautifulSoup(html_content, 'html.parser')\n",
        "\n",
        "    items = soup.find_all('div', class_='desc')\n",
        "\n",
        "    for item in items:\n",
        "        title_element = item.find(\"a\")\n",
        "        title = title_element.get(\"title\") if title_element else None\n",
        "\n",
        "        price_element = item.find('div', class_='price')\n",
        "        price = price_element.text.strip().replace(\"Giá:\", \"\") if price_element else \"\"\n",
        "\n",
        "        area_element = item.find('div', class_='area')\n",
        "        area = area_element.text.strip().replace(\"Diện tích:\", \"\") if area_element else \"\"\n",
        "\n",
        "        location_element = item.find('div', class_='location')\n",
        "        location = location_element.text.strip().replace(\"Vị trí:\", \"\") if location_element else \"\"\n",
        "\n",
        "        date_element = item.find('span', class_='date')\n",
        "        date = date_element.text.strip() if date_element else \"\"\n",
        "\n",
        "        li_element = item.find_parent('li')\n",
        "        img_tags = li_element.select('img')\n",
        "        img_src_list = [img.get('src') for img in img_tags if img.get('src')]\n",
        "\n",
        "        writer.writerow([category, title, price, area, location, date, img_src_list])\n",
        "\n",
        "# Mở một file CSV để lưu dữ liệu\n",
        "with open('nhadat.csv', 'w', newline='', encoding='utf-8-sig') as csvfile:\n",
        "    writer = csv.writer(csvfile)\n",
        "    writer.writerow(['Loại', 'Tiêu đề', 'Giá', 'Diện tích', 'Vị trí', 'Ngày đăng', 'Danh sách đường dẫn'])\n",
        "\n",
        "    for page in range(1, 1000):\n",
        "        url_ban = f\"https://dothi.net/nha-dat-ban/p{page}.htm\"\n",
        "        scrape_data(url_ban, writer, \"Nhà đất bán\")\n",
        "\n",
        "        url_cho_thue = f\"https://dothi.net/nha-dat-cho-thue/p{page}.htm\"\n",
        "        scrape_data(url_cho_thue, writer, \"Nhà đất cho thuê\")\n",
        "\n",
        "print(\"Scraping completed and data saved to nhadat.csv\")\n"
      ]
    }
  ]
}